{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Ray\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rayflow import Rayflow\n",
    "r = Rayflow.load(\"test_input.yml\", minio_volume_path=\"./minio_volume/\", mlflow_volume_path=\"./mlflow_volume/\",no_ray=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init(ignore_reinit_error=True,num_cpus=15, num_gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register MineRL environments into RLLIB using code by Julius Frost\n",
    "from minerl_rllib.envs import register\n",
    "register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registering a custom model, simple version --> fully connected network\n",
    "# The input is a 64 x 64 pixels with RGBA of game play P.O.V. --> shape = (4, 64, 64)\n",
    "# Plus other statuses such as inventory states etc. However, the MineRL competition environment\n",
    "# has use an encoder decoder model to vectorized this information.\n",
    "\n",
    "# Side note, we can also get around the following error:\n",
    "# ValueError: No default configuration for obs shape [4, 64, 64], you must specify \n",
    "# `conv_filters` manually as a model option. Default configurations are only available\n",
    "# for inputs of shape [42, 42, K] and [84, 84, K]. You may alternatively want to use \n",
    "# a custom model or preprocessor.\n",
    "\n",
    "# Because the environment wrappers by Julius Frost reshapes the output to\n",
    "# [64, 64, 4] which is what RLlib expects. (Not confirmed)\n",
    "# This way we don't need to get around it by customizing the input layer of\n",
    "# the model network.\n",
    "\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.models.torch.fcnet import FullyConnectedNetwork as TorchFC\n",
    "import torch.nn as nn\n",
    "# https://docs.ray.io/en/releases-0.8.5/rllib-examples.html\n",
    "# The register custom env and model links to custom_env.py\n",
    "# https://github.com/ray-project/ray/blob/master/rllib/examples/custom_env.py\n",
    "class TorchCustomModel(TorchModelV2, nn.Module):\n",
    "    \"\"\"Example of a PyTorch custom model that just delegates to a fc-net.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config,\n",
    "                 name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs,\n",
    "                              model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        self.torch_sub_model = TorchFC(obs_space, action_space, num_outputs,\n",
    "                                       model_config, name)\n",
    "\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        input_dict[\"obs\"] = input_dict[\"obs\"].float()\n",
    "        fc_out, _ = self.torch_sub_model(input_dict, state, seq_lens)\n",
    "        return fc_out, []\n",
    "\n",
    "    def value_function(self):\n",
    "        return torch.reshape(self.torch_sub_model.value_function(), [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the model with given name\n",
    "ModelCatalog.register_custom_model(\"fc_pov\", TorchCustomModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Name used for logging in MLFlow\n",
    "mlflow_exp_name = 'RF_MineRL_Test1'\n",
    "\n",
    "# Make sure to allocate enough CPU etc when doing Ray init earlier\n",
    "cpu_alloc_count = 8\n",
    "\n",
    "custom_model_name = 'fc_pov'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for ray and mlflow which will be parsed by Rayflow wrapper funcitions\n",
    "train_name = \"mlflow_train\"\n",
    "mlflow_logging_config = {\n",
    "    \"run_name\":\"rayflow_intial_test_run\", \n",
    "    \"run_tags\":{},\n",
    "    \"experiment_name\":mlflow_exp_name,\n",
    "    \"create_new_experiment\": True\n",
    "}\n",
    "\n",
    "trainer_config = {\n",
    "        \"env\": \"MineRLNavigateDenseVectorObf-v0\",\n",
    "         \"num_gpus\": 1.0,\n",
    "         \"num_workers\": 1,\n",
    "        # Doesnt work for now... was a fix for mlflow loading.\n",
    "#          \"num_envs_per_worker\": 1,\n",
    "#          \"num_gpus_per_worker\":1,\n",
    "         \"num_cpus_per_worker\":cpu_alloc_count,\n",
    "         \"eager\": False,\n",
    "         \"use_pytorch\": True,\n",
    "         'monitor':True, \n",
    "         \"model\": {\n",
    "             \"custom_model\": custom_model_name,\n",
    "         }    \n",
    "}\n",
    "saver_config = {\n",
    "        \"checkpoint_on_end\": True,\n",
    "        \"checkpoint_freq\": 2\n",
    "}\n",
    "stop = {\n",
    "        \"training_iteration\": 3,\n",
    "}\n",
    "tune_args = {\n",
    "        \"checkpoint_at_end\": True,\n",
    "        \"checkpoint_freq\": 2,\n",
    "\n",
    "        # NOTE: This assumes one ray worker with multiple envs\n",
    "        # Might end up as bottleneck for number of trials depending\n",
    "        # on configuration. Refer to:\n",
    "        # https://docs.ray.io/en/latest/tune/user-guide.html#parallelism-gpus\n",
    "        \"resources_per_trial\":{'gpu': 1, 'cpu':cpu_alloc_count},\n",
    "}\n",
    "\n",
    "config = {\n",
    "    \"trainer_config\":trainer_config,\n",
    "    \"logging_config\": mlflow_logging_config\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom wrapper class around the Ray Tune library\n",
    "from rayflow.tune import Tune\n",
    "t = Tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray.rllib.agents.ppo as ppo\n",
    "from ray.rllib.agents.ppo import PPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using specified configurations\n",
    "\n",
    "run_id, output_config, experiment_analysis = t.run_training(\n",
    "               trainer=PPOTrainer, \n",
    "               name=train_name, \n",
    "               stop=stop, \n",
    "               mlflow_logging_config=mlflow_logging_config, \n",
    "               trainer_config=trainer_config,\n",
    "               saver_config=saver_config,\n",
    "               tune_args=tune_args,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of loading the stored model from ML Flow to retrain/fine-tune/evaluate\n",
    "mlflow_logging_config = {\n",
    "    \"run_name\":\"rayflow_intial_test_run\", \n",
    "    \"run_tags\":{},\n",
    "    \"experiment_name\":mlflow_exp_name,\n",
    "    \"create_new_experiment\": False\n",
    "}\n",
    "config = {\n",
    "    \"trainer_config\": trainer_config,\n",
    "    \"logging_config\": mlflow_logging_config,\n",
    "    \"trainer\": PPOTrainer,\n",
    "}\n",
    "mlflow_trainer = t.restore_trainer(PPOTrainer, trainer_config, mlflow_logging_config, run_id=run_id, checkpoint_path=\"checkpoint_2\", artifact_dir=\"./mlflow_artifacts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the RayFlow docker containers\n",
    "r.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
