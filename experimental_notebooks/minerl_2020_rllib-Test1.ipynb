{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-06 13:00:00,509\tINFO resource_spec.py:231 -- Starting Ray with 15.43 GiB memory available for workers and up to 7.72 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-09-06 13:00:00,928\tINFO services.py:1193 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8266\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.7.73',\n",
       " 'raylet_ip_address': '192.168.7.73',\n",
       " 'redis_address': '192.168.7.73:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2020-09-06_13-00-00_508116_16843/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-09-06_13-00-00_508116_16843/sockets/raylet',\n",
       " 'webui_url': 'localhost:8266',\n",
       " 'session_dir': '/tmp/ray/session_2020-09-06_13-00-00_508116_16843'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Ray\n",
    "ray.shutdown()\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard URL: http://localhost:8266\n"
     ]
    }
   ],
   "source": [
    "print(\"Dashboard URL: http://{}\".format(ray.get_webui_url()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainerrl\n",
    "from chainerrl.wrappers import ContinuingTimeLimit\n",
    "from chainerrl.wrappers.atari_wrappers import FrameStack, ScaledFloatFrame\n",
    "\n",
    "# Environment wrapper borrowed from minerl sample code: \n",
    "# https://github.com/minerllabs/baselines/tree/master/general/chainerrl\n",
    "from env_wrappers import (\n",
    "    SerialDiscreteActionWrapper, CombineActionWrapper, SerialDiscreteCombineActionWrapper,\n",
    "    ContinuingTimeLimitMonitor,\n",
    "    MoveAxisWrapper, FrameSkip, ObtainPoVWrapper, PoVWithCompassAngleWrapper, GrayScaleWrapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agruments for wrapper\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.frame_skip = None\n",
    "        self.gray_scale = False\n",
    "        self.env = 'MineRLNavigateDense'\n",
    "        self.frame_stack = None\n",
    "        self.disable_action_prior = False # False=Discrete of True=CombineDiscrete\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This entire function is borrowed from MineRL demo files:\n",
    "# https://github.com/minerllabs/baselines/blob/master/general/chainerrl/baselines/ppo.py#L124\n",
    "def wrap_env(env, test):\n",
    "\n",
    "        if isinstance(env, gym.wrappers.TimeLimit):\n",
    "            # TODO re-enable this line by importing logger\n",
    "#             logger.info('Detected `gym.wrappers.TimeLimit`! Unwrap it and re-wrap our own time limit.')\n",
    "            env = env.env\n",
    "            max_episode_steps = env.spec.max_episode_steps\n",
    "            env = ContinuingTimeLimit(env, max_episode_steps=max_episode_steps)\n",
    "\n",
    "        # wrap env: observation...\n",
    "        # NOTE: wrapping order matters!\n",
    "\n",
    "        if test and args.monitor:\n",
    "            env = ContinuingTimeLimitMonitor(\n",
    "                env, os.path.join(args.outdir, 'monitor'),\n",
    "                mode='evaluation' if test else 'training', video_callable=lambda episode_id: True)\n",
    "        if args.frame_skip is not None:\n",
    "            env = FrameSkip(env, skip=args.frame_skip)\n",
    "        if args.gray_scale:\n",
    "            env = GrayScaleWrapper(env, dict_space_key='pov')\n",
    "        if args.env.startswith('MineRLNavigate'):\n",
    "            env = PoVWithCompassAngleWrapper(env)\n",
    "        else:\n",
    "            env = ObtainPoVWrapper(env)\n",
    "        env = MoveAxisWrapper(env, source=-1, destination=0)  # convert hwc -> chw as Chainer requires.\n",
    "        env = ScaledFloatFrame(env)\n",
    "        if args.frame_stack is not None and args.frame_stack > 0:\n",
    "            env = FrameStack(env, args.frame_stack, channel_order='chw')\n",
    "\n",
    "        # wrap env: action...\n",
    "        if not args.disable_action_prior:\n",
    "            env = SerialDiscreteActionWrapper(\n",
    "                env,\n",
    "                always_keys=[], reverse_keys=[], exclude_keys=['camera'], exclude_noop=False)\n",
    "        else:\n",
    "            env = CombineActionWrapper(env)\n",
    "            env = SerialDiscreteCombineActionWrapper(env)\n",
    "\n",
    "        return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register MineRL Gym Environment to RLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import minerl\n",
    "from gym import envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register MineRL Gym Environment to RLLIB\n",
    "# https://docs.ray.io/en/latest/rllib-env.html\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "def minerl_env_creator(env_config):\n",
    "    import minerl\n",
    "    \n",
    "    if 'minerl_env_name' in env_config:\n",
    "        # TODO use logger\n",
    "        print('MineRL Env Name found...')\n",
    "        env_name = env_config['minerl_env_name']\n",
    "    else:\n",
    "        # TODO use logger\n",
    "        print('No MineRL Env name specified, using MineRLNavigateDense-v0')\n",
    "        env_name = 'MineRLNavigateDense-v0'\n",
    "        \n",
    "        \n",
    "#     # Check minerl environments are imported\n",
    "#     all_envs = envs.registry.all()\n",
    "#     env_ids = [env_spec.id for env_spec in all_envs]\n",
    "#     print(env_ids)\n",
    "\n",
    "# Doesnt work, need wrapper to discretize the action space\n",
    "#     minerl_env = gym.make(env_name) \n",
    "    \n",
    "    core_env = gym.make(env_name) # A MineRLNavigate-v0 env\n",
    "    minerl_env = wrap_env(core_env, test=False)\n",
    "    \n",
    "    return minerl_env  \n",
    "\n",
    "register_env(\"minerl\", minerl_env_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# Registering a custom model, simple version --> fully connected network\n",
    "# We need this because the default configurations for the model network is\n",
    "# not compatible with the shape of the output from the MineRL environment\n",
    "# The output is a 64 x 64 pixels with RGBA of game play P.O.V. --> shape = (4, 64, 64)\n",
    "\n",
    "# Otherwise we will get:\n",
    "# ValueError: No default configuration for obs shape [4, 64, 64], you must specify \n",
    "# `conv_filters` manually as a model option. Default configurations are only available\n",
    "# for inputs of shape [42, 42, K] and [84, 84, K]. You may alternatively want to use \n",
    "# a custom model or preprocessor.\n",
    "\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.models.torch.fcnet import FullyConnectedNetwork as TorchFC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now use a fully connected network ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.ray.io/en/releases-0.8.5/rllib-examples.html\n",
    "# The register custom env and model links to custom_env.py\n",
    "# https://github.com/ray-project/ray/blob/master/rllib/examples/custom_env.py\n",
    "class TorchCustomModel(TorchModelV2, nn.Module):\n",
    "    \"\"\"Example of a PyTorch custom model that just delegates to a fc-net.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config,\n",
    "                 name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs,\n",
    "                              model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        self.torch_sub_model = TorchFC(obs_space, action_space, num_outputs,\n",
    "                                       model_config, name)\n",
    "\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        input_dict[\"obs\"] = input_dict[\"obs\"].float()\n",
    "        fc_out, _ = self.torch_sub_model(input_dict, state, seq_lens)\n",
    "        return fc_out, []\n",
    "\n",
    "    def value_function(self):\n",
    "        return torch.reshape(self.torch_sub_model.value_function(), [-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCatalog.register_custom_model(\"fc_pov\", TorchCustomModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 7.3/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/16 CPUs, 0/1 GPUs, 0.0/15.43 GiB heap, 0.0/5.32 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/blackbox/ray_results/DQN<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_minerl_8edd7_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m WARNING:tensorflow:From /home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m 2020-09-06 13:00:07,737\tWARNING deprecation.py:30 -- DeprecationWarning: `use_pytorch` has been deprecated. Use `framework=torch` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m 2020-09-06 13:00:07,737\tINFO trainer.py:632 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m /home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m No MineRL Env name specified, using MineRLNavigateDense-v0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m 2020-09-06 13:00:42,193\tINFO trainable.py:251 -- Trainable.setup took 34.820 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m 2020-09-06 13:00:42,193\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_minerl_8edd7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-06_13-01-05\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: 1968fe337450470482b03c543a767807\n",
      "  experiment_tag: '0'\n",
      "  hostname: blackbox\n",
      "  info:\n",
      "    last_target_update_ts: 1000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.19334669411182404\n",
      "        max_q: 0.12279994040727615\n",
      "        mean_q: 0.016800804063677788\n",
      "        mean_td_error: -0.0336371511220932\n",
      "        min_q: -0.04623394459486008\n",
      "    num_steps_sampled: 1000\n",
      "    num_steps_trained: 32\n",
      "    num_target_updates: 1\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.7.73\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.358823529411765\n",
      "    ram_util_percent: 35.77647058823529\n",
      "  pid: 16967\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 23.65654754638672\n",
      "  time_this_iter_s: 23.65654754638672\n",
      "  time_total_s: 23.65654754638672\n",
      "  timers:\n",
      "    learn_throughput: 291.459\n",
      "    learn_time_ms: 109.792\n",
      "  timestamp: 1599422465\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1000\n",
      "  training_iteration: 1\n",
      "  trial_id: 8edd7_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.7/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/16 CPUs, 0/1 GPUs, 0.0/15.43 GiB heap, 0.0/5.32 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/blackbox/ray_results/DQN<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_minerl_8edd7_00000</td><td>RUNNING </td><td>192.168.7.73:16967</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         23.6565</td><td style=\"text-align: right;\">1000</td><td style=\"text-align: right;\">     nan</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_minerl_8edd7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-06_13-01-39\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: 1968fe337450470482b03c543a767807\n",
      "  experiment_tag: '0'\n",
      "  hostname: blackbox\n",
      "  info:\n",
      "    last_target_update_ts: 1504\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.07108347117900848\n",
      "        max_q: 1.20137619972229\n",
      "        mean_q: 1.0611594915390015\n",
      "        mean_td_error: 0.08147308975458145\n",
      "        min_q: 1.0115444660186768\n",
      "    num_steps_sampled: 2000\n",
      "    num_steps_trained: 8032\n",
      "    num_target_updates: 2\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.7.73\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.977083333333336\n",
      "    ram_util_percent: 37.43541666666667\n",
      "  pid: 16967\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 57.45333552360535\n",
      "  time_this_iter_s: 33.79678797721863\n",
      "  time_total_s: 57.45333552360535\n",
      "  timers:\n",
      "    learn_throughput: 340.126\n",
      "    learn_time_ms: 94.083\n",
      "  timestamp: 1599422499\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2000\n",
      "  training_iteration: 2\n",
      "  trial_id: 8edd7_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.8/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/16 CPUs, 0/1 GPUs, 0.0/15.43 GiB heap, 0.0/5.32 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/blackbox/ray_results/DQN<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_minerl_8edd7_00000</td><td>RUNNING </td><td>192.168.7.73:16967</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         57.4533</td><td style=\"text-align: right;\">2000</td><td style=\"text-align: right;\">     nan</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_minerl_8edd7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-06_13-02-15\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: 1968fe337450470482b03c543a767807\n",
      "  experiment_tag: '0'\n",
      "  hostname: blackbox\n",
      "  info:\n",
      "    last_target_update_ts: 2512\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.037536777555942535\n",
      "        max_q: 1.0626637935638428\n",
      "        mean_q: 1.017970085144043\n",
      "        mean_td_error: 0.049974989145994186\n",
      "        min_q: 0.9332568645477295\n",
      "    num_steps_sampled: 3000\n",
      "    num_steps_trained: 16032\n",
      "    num_target_updates: 4\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.7.73\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.486538461538462\n",
      "    ram_util_percent: 37.93269230769231\n",
      "  pid: 16967\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 93.4831485748291\n",
      "  time_this_iter_s: 36.029813051223755\n",
      "  time_total_s: 93.4831485748291\n",
      "  timers:\n",
      "    learn_throughput: 329.71\n",
      "    learn_time_ms: 97.055\n",
      "  timestamp: 1599422535\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3000\n",
      "  training_iteration: 3\n",
      "  trial_id: 8edd7_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.9/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/16 CPUs, 0/1 GPUs, 0.0/15.43 GiB heap, 0.0/5.32 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/blackbox/ray_results/DQN<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_minerl_8edd7_00000</td><td>RUNNING </td><td>192.168.7.73:16967</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         93.4831</td><td style=\"text-align: right;\">3000</td><td style=\"text-align: right;\">     nan</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_minerl_8edd7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-06_13-02-52\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: 1968fe337450470482b03c543a767807\n",
      "  experiment_tag: '0'\n",
      "  hostname: blackbox\n",
      "  info:\n",
      "    last_target_update_ts: 3520\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.022014491260051727\n",
      "        max_q: 0.9397761821746826\n",
      "        mean_q: 0.8950495719909668\n",
      "        mean_td_error: -0.043474163860082626\n",
      "        min_q: 0.8329958319664001\n",
      "    num_steps_sampled: 4000\n",
      "    num_steps_trained: 24032\n",
      "    num_target_updates: 6\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.7.73\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.51153846153846\n",
      "    ram_util_percent: 38.19230769230769\n",
      "  pid: 16967\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 129.80799865722656\n",
      "  time_this_iter_s: 36.32485008239746\n",
      "  time_total_s: 129.80799865722656\n",
      "  timers:\n",
      "    learn_throughput: 332.46\n",
      "    learn_time_ms: 96.252\n",
      "  timestamp: 1599422572\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4000\n",
      "  training_iteration: 4\n",
      "  trial_id: 8edd7_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.0/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/16 CPUs, 0/1 GPUs, 0.0/15.43 GiB heap, 0.0/5.32 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/blackbox/ray_results/DQN<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_minerl_8edd7_00000</td><td>RUNNING </td><td>192.168.7.73:16967</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         129.808</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">     nan</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_minerl_8edd7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-06_13-03-28\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: 1968fe337450470482b03c543a767807\n",
      "  experiment_tag: '0'\n",
      "  hostname: blackbox\n",
      "  info:\n",
      "    last_target_update_ts: 4528\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.01348408218473196\n",
      "        max_q: 1.0141932964324951\n",
      "        mean_q: 0.9728438258171082\n",
      "        mean_td_error: -0.03279804065823555\n",
      "        min_q: 0.809669554233551\n",
      "    num_steps_sampled: 5000\n",
      "    num_steps_trained: 32032\n",
      "    num_target_updates: 8\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.7.73\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.174509803921566\n",
      "    ram_util_percent: 38.57647058823529\n",
      "  pid: 16967\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 165.82624316215515\n",
      "  time_this_iter_s: 36.01824450492859\n",
      "  time_total_s: 165.82624316215515\n",
      "  timers:\n",
      "    learn_throughput: 342.492\n",
      "    learn_time_ms: 93.433\n",
      "  timestamp: 1599422608\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5000\n",
      "  training_iteration: 5\n",
      "  trial_id: 8edd7_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.1/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/16 CPUs, 0/1 GPUs, 0.0/15.43 GiB heap, 0.0/5.32 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/blackbox/ray_results/DQN<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_minerl_8edd7_00000</td><td>RUNNING </td><td>192.168.7.73:16967</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         165.826</td><td style=\"text-align: right;\">5000</td><td style=\"text-align: right;\">     nan</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-06 13:04:04,510\tERROR trial_runner.py:523 -- Trial DQN_minerl_8edd7_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 471, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 430, in fetch_result\n",
      "    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/worker.py\", line 1538, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(Error): \u001b[36mray::DQN.train()\u001b[39m (pid=16967, ip=192.168.7.73)\n",
      "  File \"python/ray/_raylet.pyx\", line 479, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 432, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 522, in train\n",
      "    raise e\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 508, in train\n",
      "    result = Trainable.train(self)\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/tune/trainable.py\", line 332, in train\n",
      "    result = self.step()\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 110, in step\n",
      "    res = next(self.train_exec_impl)\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/util/iter.py\", line 758, in __next__\n",
      "    return next(self.built_iterator)\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/util/iter.py\", line 785, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/util/iter.py\", line 845, in apply_filter\n",
      "    for item in it:\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/util/iter.py\", line 845, in apply_filter\n",
      "    for item in it:\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/util/iter.py\", line 785, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/util/iter.py\", line 845, in apply_filter\n",
      "    for item in it:\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/util/iter.py\", line 1078, in build_union\n",
      "    item = next(it)\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/util/iter.py\", line 758, in __next__\n",
      "    return next(self.built_iterator)\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/util/iter.py\", line 785, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/util/iter.py\", line 785, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/util/iter.py\", line 785, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/rllib/execution/rollout_ops.py\", line 70, in sampler\n",
      "    yield workers.local_worker().sample()\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 563, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py\", line 71, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py\", line 181, in get_data\n",
      "    item = next(self.rollout_provider)\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py\", line 536, in _env_runner\n",
      "    _use_trajectory_view_api=_use_trajectory_view_api)\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py\", line 805, in _process_observations\n",
      "    env_id)\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/rllib/env/base_env.py\", line 350, in try_reset\n",
      "    return {_DUMMY_AGENT_ID: self.vector_env.reset_at(env_id)}\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/rllib/env/vector_env.py\", line 137, in reset_at\n",
      "    return self.envs[index].reset()\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/gym/wrappers/monitor.py\", line 37, in reset\n",
      "    self._before_reset()\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/gym/wrappers/monitor.py\", line 177, in _before_reset\n",
      "    self.stats_recorder.before_reset()\n",
      "  File \"/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/gym/wrappers/monitoring/stats_recorder.py\", line 68, in before_reset\n",
      "    raise error.Error(\"Tried to reset environment which is not done. While the monitor is active for {}, you cannot call reset() unless the episode is over.\".format(self.env_id))\n",
      "gym.error.Error: Tried to reset environment which is not done. While the monitor is active for MineRLNavigateDense-v0, you cannot call reset() unless the episode is over.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.3/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/16 CPUs, 0/1 GPUs, 0.0/15.43 GiB heap, 0.0/5.32 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/blackbox/ray_results/DQN<br>Number of trials: 1 (1 ERROR)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_minerl_8edd7_00000</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         165.826</td><td style=\"text-align: right;\">5000</td><td style=\"text-align: right;\">     nan</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                       </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_minerl_8edd7_00000</td><td style=\"text-align: right;\">           1</td><td>/home/blackbox/ray_results/DQN/DQN_minerl_0_2020-09-06_13-00-0581weh38t/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.3/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/16 CPUs, 0/1 GPUs, 0.0/15.43 GiB heap, 0.0/5.32 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/blackbox/ray_results/DQN<br>Number of trials: 1 (1 ERROR)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_minerl_8edd7_00000</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         165.826</td><td style=\"text-align: right;\">5000</td><td style=\"text-align: right;\">     nan</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                       </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_minerl_8edd7_00000</td><td style=\"text-align: right;\">           1</td><td>/home/blackbox/ray_results/DQN/DQN_minerl_0_2020-09-06_13-00-0581weh38t/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m *** Aborted at 1599422647 (unix time) try \"date -d @1599422647\" if you are using GNU date ***\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m PC: @                0x0 (unknown)\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m *** SIGSEGV (@0x7f45e8ff99d0) received by PID 17270 (TID 0x7f460ba94740) from PID 18446744073323649488; stack trace: ***\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x7f460be053c0 (unknown)\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x7f460bdfaaab __pthread_clockjoin_ex\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x7f46099d02d3 std::thread::join()\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x7f4609f01493 ray::gcs::GlobalStateAccessor::Disconnect()\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x7f4609da0fbc __pyx_pw_3ray_7_raylet_19GlobalStateAccessor_5disconnect()\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dccaeb71 _PyMethodDef_RawFastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dccb5aef _PyMethodDescr_FastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dcd1a37c _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dccae20b _PyFunction_FastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dcd15e70 _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dcc5e2b9 _PyEval_EvalCodeWithName\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dccae435 _PyFunction_FastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dcd15be6 _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dcc5e2b9 _PyEval_EvalCodeWithName\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dcc5f3e5 _PyFunction_FastCallDict\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dccc3c70 PyErr_CheckSignals\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dcccf9c6 time_sleep\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dccaeabd _PyMethodDef_RawFastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dccaedb1 _PyCFunction_FastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dcd1a5be _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dcc5eb00 _PyEval_EvalCodeWithName\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dcc5f3e5 _PyFunction_FastCallDict\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dcd1751a _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dccae20b _PyFunction_FastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dcd15e70 _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dccae20b _PyFunction_FastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dcd15e70 _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dccae20b _PyFunction_FastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dcd15e70 _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dcc5f31b _PyFunction_FastCallDict\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dcc7db93 _PyObject_Call_Prepend\n",
      "\u001b[2m\u001b[36m(pid=16967)\u001b[0m     @     0x5588dccb50aa slot_tp_init\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [DQN_minerl_8edd7_00000])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2ee78c2411d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                  \u001b[0;34m'monitor'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                  \"model\": {\n\u001b[0;32m---> 10\u001b[0;31m                     \u001b[0;34m\"custom_model\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"fc_pov\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                     }\n\u001b[1;32m     12\u001b[0m                  }\n",
      "\u001b[0;32m~/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, stop, config, resources_per_trial, num_samples, local_dir, upload_dir, trial_name_creator, loggers, sync_to_cloud, sync_to_driver, checkpoint_freq, checkpoint_at_end, sync_on_checkpoint, keep_checkpoints_num, checkpoint_score_attr, global_checkpoint_period, export_formats, max_failures, fail_fast, restore, search_alg, scheduler, with_server, server_port, verbose, progress_reporter, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, return_trials, ray_auto_init)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [DQN_minerl_8edd7_00000])"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from ray.rllib.agents.dqn import DQNTrainer\n",
    "\n",
    "tune.run(DQNTrainer,\n",
    "         config={\"env\": \"minerl\",\n",
    "                 \"use_pytorch\": True,\n",
    "                 'monitor':True, \n",
    "                 \"model\": {\n",
    "                    \"custom_model\": \"fc_pov\",\n",
    "                    }\n",
    "                 }\n",
    "        )#,\n",
    "         #stop={\"training_iteration\": 2, \"timesteps_total\": 1000})  \n",
    "# Config notes:\n",
    "# \"log_level\": \"INFO\" for verbose,\n",
    "# \"eager\": True for eager execution,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
