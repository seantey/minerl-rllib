{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-26 17:18:18,361\tINFO resource_spec.py:231 -- Starting Ray with 14.01 GiB memory available for workers and up to 7.02 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-09-26 17:18:18,774\tINFO services.py:1193 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.7.73',\n",
       " 'raylet_ip_address': '192.168.7.73',\n",
       " 'redis_address': '192.168.7.73:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2020-09-26_17-18-18_360183_30339/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-09-26_17-18-18_360183_30339/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-09-26_17-18-18_360183_30339'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Ray\n",
    "ray.shutdown()\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard URL: http://localhost:8265\n"
     ]
    }
   ],
   "source": [
    "print(\"Dashboard URL: http://{}\".format(ray.get_webui_url()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainerrl\n",
    "from chainerrl.wrappers import ContinuingTimeLimit\n",
    "from chainerrl.wrappers.atari_wrappers import FrameStack, ScaledFloatFrame\n",
    "\n",
    "# Environment wrapper borrowed from minerl sample code: \n",
    "# https://github.com/minerllabs/baselines/tree/master/general/chainerrl\n",
    "from env_wrappers import (\n",
    "    SerialDiscreteActionWrapper, CombineActionWrapper, SerialDiscreteCombineActionWrapper,\n",
    "    ContinuingTimeLimitMonitor,\n",
    "    MoveAxisWrapper, FrameSkip, ObtainPoVWrapper, PoVWithCompassAngleWrapper, GrayScaleWrapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agruments for wrapper\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.frame_skip = None\n",
    "        self.gray_scale = False\n",
    "        self.env = 'MineRLNavigateDense'\n",
    "        self.frame_stack = None\n",
    "        self.disable_action_prior = False # False=Discrete of True=CombineDiscrete\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This entire function is borrowed from MineRL demo files:\n",
    "# https://github.com/minerllabs/baselines/blob/master/general/chainerrl/baselines/ppo.py#L124\n",
    "def wrap_env(env, test):\n",
    "\n",
    "        if isinstance(env, gym.wrappers.TimeLimit):\n",
    "            # TODO re-enable this line by importing logger\n",
    "#             logger.info('Detected `gym.wrappers.TimeLimit`! Unwrap it and re-wrap our own time limit.')\n",
    "            env = env.env\n",
    "            max_episode_steps = env.spec.max_episode_steps\n",
    "            env = ContinuingTimeLimit(env, max_episode_steps=max_episode_steps)\n",
    "\n",
    "        # wrap env: observation...\n",
    "        # NOTE: wrapping order matters!\n",
    "\n",
    "        if test and args.monitor:\n",
    "            env = ContinuingTimeLimitMonitor(\n",
    "                env, os.path.join(args.outdir, 'monitor'),\n",
    "                mode='evaluation' if test else 'training', video_callable=lambda episode_id: True)\n",
    "        if args.frame_skip is not None:\n",
    "            env = FrameSkip(env, skip=args.frame_skip)\n",
    "        if args.gray_scale:\n",
    "            env = GrayScaleWrapper(env, dict_space_key='pov')\n",
    "        if args.env.startswith('MineRLNavigate'):\n",
    "            env = PoVWithCompassAngleWrapper(env)\n",
    "        else:\n",
    "            env = ObtainPoVWrapper(env)\n",
    "        env = MoveAxisWrapper(env, source=-1, destination=0)  # convert hwc -> chw as Chainer requires.\n",
    "        env = ScaledFloatFrame(env)\n",
    "        if args.frame_stack is not None and args.frame_stack > 0:\n",
    "            env = FrameStack(env, args.frame_stack, channel_order='chw')\n",
    "\n",
    "        # wrap env: action...\n",
    "        if not args.disable_action_prior:\n",
    "            env = SerialDiscreteActionWrapper(\n",
    "                env,\n",
    "                always_keys=[], reverse_keys=[], exclude_keys=['camera'], exclude_noop=False)\n",
    "        else:\n",
    "            env = CombineActionWrapper(env)\n",
    "            env = SerialDiscreteCombineActionWrapper(env)\n",
    "\n",
    "        return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register MineRL Gym Environment to RLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import minerl\n",
    "from gym import envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register MineRL Gym Environment to RLLIB\n",
    "# https://docs.ray.io/en/latest/rllib-env.html\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "def minerl_env_creator(env_config):\n",
    "    import minerl\n",
    "    \n",
    "    if 'minerl_env_name' in env_config:\n",
    "        # TODO use logger\n",
    "        print('MineRL Env Name found...')\n",
    "        env_name = env_config['minerl_env_name']\n",
    "    else:\n",
    "        # TODO use logger\n",
    "        print('No MineRL Env name specified, using MineRLNavigateDense-v0')\n",
    "        env_name = 'MineRLNavigateDense-v0'\n",
    "        \n",
    "        \n",
    "#     # Check minerl environments are imported\n",
    "#     all_envs = envs.registry.all()\n",
    "#     env_ids = [env_spec.id for env_spec in all_envs]\n",
    "#     print(env_ids)\n",
    "\n",
    "# Doesnt work, need wrapper to discretize the action space\n",
    "#     minerl_env = gym.make(env_name) \n",
    "    \n",
    "    core_env = gym.make(env_name) # A MineRLNavigate-v0 env\n",
    "    minerl_env = wrap_env(core_env, test=False)\n",
    "    \n",
    "    return minerl_env  \n",
    "\n",
    "register_env(\"minerl\", minerl_env_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# Registering a custom model, simple version --> fully connected network\n",
    "# We need this because the default configurations for the model network is\n",
    "# not compatible with the shape of the output from the MineRL environment\n",
    "# The output is a 64 x 64 pixels with RGBA of game play P.O.V. --> shape = (4, 64, 64)\n",
    "\n",
    "# Otherwise we will get:\n",
    "# ValueError: No default configuration for obs shape [4, 64, 64], you must specify \n",
    "# `conv_filters` manually as a model option. Default configurations are only available\n",
    "# for inputs of shape [42, 42, K] and [84, 84, K]. You may alternatively want to use \n",
    "# a custom model or preprocessor.\n",
    "\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.models.torch.fcnet import FullyConnectedNetwork as TorchFC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now use a fully connected network ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.ray.io/en/releases-0.8.5/rllib-examples.html\n",
    "# The register custom env and model links to custom_env.py\n",
    "# https://github.com/ray-project/ray/blob/master/rllib/examples/custom_env.py\n",
    "class TorchCustomModel(TorchModelV2, nn.Module):\n",
    "    \"\"\"Example of a PyTorch custom model that just delegates to a fc-net.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config,\n",
    "                 name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs,\n",
    "                              model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        self.torch_sub_model = TorchFC(obs_space, action_space, num_outputs,\n",
    "                                       model_config, name)\n",
    "\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        input_dict[\"obs\"] = input_dict[\"obs\"].float()\n",
    "        fc_out, _ = self.torch_sub_model(input_dict, state, seq_lens)\n",
    "        return fc_out, []\n",
    "\n",
    "    def value_function(self):\n",
    "        return torch.reshape(self.torch_sub_model.value_function(), [-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCatalog.register_custom_model(\"fc_pov\", TorchCustomModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.6/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/16 CPUs, 0/1 GPUs, 0.0/14.01 GiB heap, 0.0/4.83 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/blackbox/ray_results/DQN<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_minerl_0af08_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m WARNING:tensorflow:From /home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m 2020-09-26 17:19:03,172\tWARNING deprecation.py:30 -- DeprecationWarning: `use_pytorch` has been deprecated. Use `framework=torch` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m 2020-09-26 17:19:03,172\tINFO trainer.py:632 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m /home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m No MineRL Env name specified, using MineRLNavigateDense-v0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m 2020-09-26 17:19:37,321\tINFO trainable.py:251 -- Trainable.setup took 34.521 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m 2020-09-26 17:19:37,322\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_minerl_0af08_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-26_17-20-05\n",
      "  done: true\n",
      "  episode_len_mean: .nan\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: 230bd0b49c5a4629afe1ef45bbdd6021\n",
      "  experiment_tag: '0'\n",
      "  hostname: blackbox\n",
      "  info:\n",
      "    last_target_update_ts: 1000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.518851101398468\n",
      "        max_q: 0.12171119451522827\n",
      "        mean_q: -0.004640852101147175\n",
      "        mean_td_error: -0.051513463258743286\n",
      "        min_q: -0.12466123700141907\n",
      "    num_steps_sampled: 1000\n",
      "    num_steps_trained: 32\n",
      "    num_target_updates: 1\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.7.73\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 36.55609756097561\n",
      "    ram_util_percent: 43.8829268292683\n",
      "  pid: 30652\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 28.057227611541748\n",
      "  time_this_iter_s: 28.057227611541748\n",
      "  time_total_s: 28.057227611541748\n",
      "  timers:\n",
      "    learn_throughput: 266.269\n",
      "    learn_time_ms: 120.179\n",
      "  timestamp: 1601166005\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1000\n",
      "  training_iteration: 1\n",
      "  trial_id: 0af08_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/16 CPUs, 0/1 GPUs, 0.0/14.01 GiB heap, 0.0/4.83 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/blackbox/ray_results/DQN<br>Number of trials: 1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_minerl_0af08_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         28.0572</td><td style=\"text-align: right;\">1000</td><td style=\"text-align: right;\">     nan</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/16 CPUs, 0/1 GPUs, 0.0/14.01 GiB heap, 0.0/4.83 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/blackbox/ray_results/DQN<br>Number of trials: 1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_minerl_0af08_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         28.0572</td><td style=\"text-align: right;\">1000</td><td style=\"text-align: right;\">     nan</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m *** Aborted at 1601166008 (unix time) try \"date -d @1601166008\" if you are using GNU date ***\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m PC: @                0x0 (unknown)\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m *** SIGSEGV (@0x7ff2fcff99d0) received by PID 31010 (TID 0x7ff31f930740) from PID 18446744073659193808; stack trace: ***\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x7ff31fca13c0 (unknown)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7fd68f975f10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x7ff31fc96aab __pthread_clockjoin_ex\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x7ff31d86c2d3 std::thread::join()\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x7ff31dd9d493 ray::gcs::GlobalStateAccessor::Disconnect()\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x7ff31dc3cfbc __pyx_pw_3ray_7_raylet_19GlobalStateAccessor_5disconnect()\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x5622711deb71 _PyMethodDef_RawFastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x5622711e5aef _PyMethodDescr_FastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x56227124a37c _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x5622711de20b _PyFunction_FastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x562271245e70 _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x56227118e2b9 _PyEval_EvalCodeWithName\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x5622711de435 _PyFunction_FastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x562271245be6 _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x56227118e2b9 _PyEval_EvalCodeWithName\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x56227118f3e5 _PyFunction_FastCallDict\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x5622711f3c70 PyErr_CheckSignals\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x5622711ff9c6 time_sleep\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x5622711deabd _PyMethodDef_RawFastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x5622711dedb1 _PyCFunction_FastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x56227124a5be _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x56227118eb00 _PyEval_EvalCodeWithName\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x56227118f3e5 _PyFunction_FastCallDict\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x56227124751a _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x5622711de20b _PyFunction_FastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x562271245e70 _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x5622711de20b _PyFunction_FastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x562271245e70 _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x5622711de20b _PyFunction_FastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x562271245e70 _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x56227118f31b _PyFunction_FastCallDict\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x5622711adb93 _PyObject_Call_Prepend\n",
      "\u001b[2m\u001b[36m(pid=30652)\u001b[0m     @     0x5622711e50aa slot_tp_init\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from ray.rllib.agents.dqn import DQNTrainer\n",
    "\n",
    "tune.run(DQNTrainer,\n",
    "         config={\"env\": \"minerl\",\n",
    "                 \"use_pytorch\": True,\n",
    "                 'monitor':True, \n",
    "                 \"model\": {\n",
    "                    \"custom_model\": \"fc_pov\",\n",
    "                    }\n",
    "                 }\n",
    "        #),\n",
    "         ,stop={\"training_iteration\": 2, \"timesteps_total\": 1000})  \n",
    "# Config notes:\n",
    "# \"log_level\": \"INFO\" for verbose,\n",
    "# \"eager\": True for eager execution,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
