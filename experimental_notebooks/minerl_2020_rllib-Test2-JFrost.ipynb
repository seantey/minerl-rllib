{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-27 16:02:45,062\tINFO resource_spec.py:223 -- Starting Ray with 35.89 GiB memory available for workers and up to 17.97 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-09-27 16:02:45,486\tINFO services.py:1191 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.65',\n",
       " 'raylet_ip_address': '192.168.1.65',\n",
       " 'redis_address': '192.168.1.65:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2020-09-27_16-02-45_061032_20740/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-09-27_16-02-45_061032_20740/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-09-27_16-02-45_061032_20740'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Ray\n",
    "ray.shutdown()\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard URL: http://localhost:8265\n"
     ]
    }
   ],
   "source": [
    "print(\"Dashboard URL: http://{}\".format(ray.get_webui_url()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register MineRL Gym Environment to RLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shyam/anaconda3/envs/py38/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import minerl\n",
    "from gym import envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minerl_rllib.envs.env import MineRLRandomDebugEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register MineRL Gym Environment to RLLIB\n",
    "# https://docs.ray.io/en/latest/rllib-env.html\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "def minerl_env_creator(env_config):\n",
    "    import minerl\n",
    "    \n",
    "    if 'minerl_env_name' in env_config:\n",
    "        # TODO use logger\n",
    "        print('MineRL Env Name found...')\n",
    "        env_name = env_config['minerl_env_name']\n",
    "    else:\n",
    "        # TODO use logger\n",
    "        print('No MineRL Env name specified, using MineRLNavigateDense-v0')\n",
    "        env_name = 'MineRLNavigateDense-v0'\n",
    "        \n",
    "        \n",
    "#     # Check minerl environments are imported\n",
    "#     # This only checks Gym environment not the ones registered in Ray!\n",
    "#     all_envs = envs.registry.all()\n",
    "#     env_ids = [env_spec.id for env_spec in all_envs]\n",
    "#     print(env_ids)\n",
    "\n",
    "# This doesnt work, need wrapper to discretize the action space for DQN\n",
    "#     minerl_env = gym.make(env_name) \n",
    "    \n",
    "    # Second version but has .nan rewards\n",
    "#     core_env = gym.make(env_name) # A MineRLNavigate-v0 env\n",
    "#     minerl_env = wrap_env(core_env, test=False)\n",
    "    \n",
    "#     minerl_env = gym.make('MineRLNavigateDense-v0')\n",
    "    \n",
    "    return minerl_env  \n",
    "\n",
    "register_env(\"minerl\", minerl_env_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minerl_rllib.envs import register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "obfuscated_envs = minerl.herobraine.envs.obfuscated_envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function minerl.herobraine.wrappers.obfuscation_wrapper.Obfuscated._get_obfuscator.<locals>.make_func.<locals>.func(x)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obfuscated_envs[0].ac_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.0/62.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/24 CPUs, 1/1 GPUs, 0.0/35.89 GiB heap, 0.0/12.35 GiB objects (0/1.0 GPUType:RTX)<br>Result logdir: /home/shyam/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_29055_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=20860)\u001b[0m WARNING:tensorflow:From /home/shyam/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=20860)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=20860)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=20860)\u001b[0m /home/shyam/anaconda3/envs/py38/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=20860)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=20860)\u001b[0m 2020-09-27 16:07:08,204\tWARNING deprecation.py:29 -- DeprecationWarning: `use_pytorch` has been deprecated. Use `framework=torch` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=20860)\u001b[0m 2020-09-27 16:07:08,204\tWARNING deprecation.py:29 -- DeprecationWarning: `eager` has been deprecated. Use `framework=tfe` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=20860)\u001b[0m 2020-09-27 16:07:08,204\tINFO trainer.py:630 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=20860)\u001b[0m 2020-09-27 16:07:11,452\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m WARNING:tensorflow:From /home/shyam/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m /home/shyam/anaconda3/envs/py38/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m /home/shyam/anaconda3/envs/py38/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:149: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MineRLNavigateDenseVectorObf-v0_29055_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-27_16-08-55\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: cd52130b4cb14f188950a86134d66947\n",
      "  experiment_tag: '0'\n",
      "  hostname: kokkgoblin\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.2\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 90.75303053855896\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.022007984633091837\n",
      "        policy_loss: -0.02486593060893938\n",
      "        total_loss: 0.017681708675809205\n",
      "        vf_explained_var: 0.00016084685921669006\n",
      "        vf_loss: 0.03814604436047375\n",
      "    num_steps_sampled: 4000\n",
      "    num_steps_trained: 4000\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.473825503355705\n",
      "    ram_util_percent: 26.73087248322147\n",
      "  pid: 20860\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 104.16804122924805\n",
      "  time_this_iter_s: 104.16804122924805\n",
      "  time_total_s: 104.16804122924805\n",
      "  timers:\n",
      "    learn_throughput: 274.431\n",
      "    learn_time_ms: 14575.608\n",
      "    sample_throughput: 44.667\n",
      "    sample_time_ms: 89552.274\n",
      "    update_time_ms: 14.886\n",
      "  timestamp: 1601248135\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4000\n",
      "  training_iteration: 1\n",
      "  trial_id: '29055_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.6/62.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/24 CPUs, 1/1 GPUs, 0.0/35.89 GiB heap, 0.0/12.35 GiB objects (0/1.0 GPUType:RTX)<br>Result logdir: /home/shyam/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_29055_00000</td><td>RUNNING </td><td>192.168.1.65:20860</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         104.168</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">     nan</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=20874)\u001b[0m WARNING:tensorflow:From /home/shyam/anaconda3/envs/py38/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py:869: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=20874)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=20874)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=20877)\u001b[0m WARNING:tensorflow:From /home/shyam/anaconda3/envs/py38/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py:869: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=20877)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=20877)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m /home/shyam/anaconda3/envs/py38/lib/python3.8/site-packages/minerl/herobraine/wrappers/obfuscation_wrapper.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m   x[..., a:b] = e_x / e_x.sum(axis=-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MineRLNavigateDenseVectorObf-v0_29055_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-27_16-10-07\n",
      "  done: false\n",
      "  episode_len_mean: 6000.0\n",
      "  episode_reward_max: 2.3164520263671875\n",
      "  episode_reward_mean: 2.3164520263671875\n",
      "  episode_reward_min: 2.3164520263671875\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1\n",
      "  experiment_id: cd52130b4cb14f188950a86134d66947\n",
      "  experiment_tag: '0'\n",
      "  hostname: kokkgoblin\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.30000000000000004\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 90.83904385566711\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.020802510727662593\n",
      "        policy_loss: -0.027893902675714344\n",
      "        total_loss: 0.05949112452799454\n",
      "        vf_explained_var: -1.30385160446167e-08\n",
      "        vf_loss: 0.08114427141845226\n",
      "    num_steps_sampled: 8000\n",
      "    num_steps_trained: 8000\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.428155339805823\n",
      "    ram_util_percent: 31.26893203883494\n",
      "  pid: 20860\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 12.284258755575552\n",
      "    mean_inference_ms: 3.231618243773987\n",
      "    mean_processing_ms: 2.8552034023090864\n",
      "  time_since_restore: 176.16794538497925\n",
      "  time_this_iter_s: 71.9999041557312\n",
      "  time_total_s: 176.16794538497925\n",
      "  timers:\n",
      "    learn_throughput: 314.645\n",
      "    learn_time_ms: 12712.742\n",
      "    sample_throughput: 53.091\n",
      "    sample_time_ms: 75341.875\n",
      "    update_time_ms: 12.299\n",
      "  timestamp: 1601248207\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8000\n",
      "  training_iteration: 2\n",
      "  trial_id: '29055_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.8/62.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/24 CPUs, 1/1 GPUs, 0.0/35.89 GiB heap, 0.0/12.35 GiB objects (0/1.0 GPUType:RTX)<br>Result logdir: /home/shyam/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_29055_00000</td><td>RUNNING </td><td>192.168.1.65:20860</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         176.168</td><td style=\"text-align: right;\">8000</td><td style=\"text-align: right;\"> 2.31645</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MineRLNavigateDenseVectorObf-v0_29055_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-27_16-11-16\n",
      "  done: false\n",
      "  episode_len_mean: 6000.0\n",
      "  episode_reward_max: 2.3164520263671875\n",
      "  episode_reward_mean: 0.92059326171875\n",
      "  episode_reward_min: -0.4752655029296875\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 2\n",
      "  experiment_id: cd52130b4cb14f188950a86134d66947\n",
      "  experiment_tag: '0'\n",
      "  hostname: kokkgoblin\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.45000000000000007\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 90.86713719367981\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013891473470721394\n",
      "        policy_loss: -0.025279024586779997\n",
      "        total_loss: 0.18496823887107894\n",
      "        vf_explained_var: -9.313225746154785e-09\n",
      "        vf_loss: 0.20399610325694084\n",
      "    num_steps_sampled: 12000\n",
      "    num_steps_trained: 12000\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.616326530612252\n",
      "    ram_util_percent: 32.03265306122449\n",
      "  pid: 20860\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 11.244295135717117\n",
      "    mean_inference_ms: 3.186434612219108\n",
      "    mean_processing_ms: 3.2933494606300417\n",
      "  time_since_restore: 245.08443665504456\n",
      "  time_this_iter_s: 68.91649127006531\n",
      "  time_total_s: 245.08443665504456\n",
      "  timers:\n",
      "    learn_throughput: 331.812\n",
      "    learn_time_ms: 12055.031\n",
      "    sample_throughput: 57.46\n",
      "    sample_time_ms: 69614.049\n",
      "    update_time_ms: 11.321\n",
      "  timestamp: 1601248276\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12000\n",
      "  training_iteration: 3\n",
      "  trial_id: '29055_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.1/62.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/24 CPUs, 1/1 GPUs, 0.0/35.89 GiB heap, 0.0/12.35 GiB objects (0/1.0 GPUType:RTX)<br>Result logdir: /home/shyam/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_29055_00000</td><td>RUNNING </td><td>192.168.1.65:20860</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         245.084</td><td style=\"text-align: right;\">12000</td><td style=\"text-align: right;\">0.920593</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MineRLNavigateDenseVectorObf-v0_29055_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-27_16-12-07\n",
      "  done: false\n",
      "  episode_len_mean: 6000.0\n",
      "  episode_reward_max: 2.3164520263671875\n",
      "  episode_reward_mean: 0.92059326171875\n",
      "  episode_reward_min: -0.4752655029296875\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 2\n",
      "  experiment_id: cd52130b4cb14f188950a86134d66947\n",
      "  experiment_tag: '0'\n",
      "  hostname: kokkgoblin\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.45000000000000007\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 90.87158632278442\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.021321991458535194\n",
      "        policy_loss: -0.03796067350776866\n",
      "        total_loss: 0.2080332895857282\n",
      "        vf_explained_var: 0.0006457306444644928\n",
      "        vf_loss: 0.23639906803146005\n",
      "    num_steps_sampled: 16000\n",
      "    num_steps_trained: 16000\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.056164383561647\n",
      "    ram_util_percent: 32.26849315068494\n",
      "  pid: 20860\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 11.244295135717117\n",
      "    mean_inference_ms: 3.186434612219108\n",
      "    mean_processing_ms: 3.2933494606300417\n",
      "  time_since_restore: 296.2176125049591\n",
      "  time_this_iter_s: 51.13317584991455\n",
      "  time_total_s: 296.2176125049591\n",
      "  timers:\n",
      "    learn_throughput: 340.029\n",
      "    learn_time_ms: 11763.703\n",
      "    sample_throughput: 64.24\n",
      "    sample_time_ms: 62266.48\n",
      "    update_time_ms: 10.755\n",
      "  timestamp: 1601248327\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16000\n",
      "  training_iteration: 4\n",
      "  trial_id: '29055_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.2/62.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/24 CPUs, 1/1 GPUs, 0.0/35.89 GiB heap, 0.0/12.35 GiB objects (0/1.0 GPUType:RTX)<br>Result logdir: /home/shyam/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_29055_00000</td><td>RUNNING </td><td>192.168.1.65:20860</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         296.218</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\">0.920593</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MineRLNavigateDenseVectorObf-v0_29055_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-27_16-13-23\n",
      "  done: false\n",
      "  episode_len_mean: 6000.0\n",
      "  episode_reward_max: 2.3164520263671875\n",
      "  episode_reward_mean: -0.5280609130859375\n",
      "  episode_reward_min: -3.4253692626953125\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 3\n",
      "  experiment_id: cd52130b4cb14f188950a86134d66947\n",
      "  experiment_tag: '0'\n",
      "  hostname: kokkgoblin\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.675\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 90.75740218162537\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.018653842620551586\n",
      "        policy_loss: -0.035922828246839345\n",
      "        total_loss: 0.15098891535308212\n",
      "        vf_explained_var: 0.00024526193737983704\n",
      "        vf_loss: 0.1743203983642161\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 20000\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.360185185185188\n",
      "    ram_util_percent: 32.19166666666666\n",
      "  pid: 20860\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 10.449567685883261\n",
      "    mean_inference_ms: 3.15196207952566\n",
      "    mean_processing_ms: 3.3717907957852025\n",
      "  time_since_restore: 371.6498200893402\n",
      "  time_this_iter_s: 75.4322075843811\n",
      "  time_total_s: 371.6498200893402\n",
      "  timers:\n",
      "    learn_throughput: 346.046\n",
      "    learn_time_ms: 11559.147\n",
      "    sample_throughput: 63.747\n",
      "    sample_time_ms: 62747.785\n",
      "    update_time_ms: 10.614\n",
      "  timestamp: 1601248403\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 5\n",
      "  trial_id: '29055_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.1/62.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/24 CPUs, 1/1 GPUs, 0.0/35.89 GiB heap, 0.0/12.35 GiB objects (0/1.0 GPUType:RTX)<br>Result logdir: /home/shyam/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_29055_00000</td><td>RUNNING </td><td>192.168.1.65:20860</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">          371.65</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\">-0.528061</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MineRLNavigateDenseVectorObf-v0_29055_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-27_16-14-32\n",
      "  done: false\n",
      "  episode_len_mean: 6000.0\n",
      "  episode_reward_max: 3.2809486389160156\n",
      "  episode_reward_mean: 0.4241914749145508\n",
      "  episode_reward_min: -3.4253692626953125\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 4\n",
      "  experiment_id: cd52130b4cb14f188950a86134d66947\n",
      "  experiment_tag: '0'\n",
      "  hostname: kokkgoblin\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.675\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 90.71402263641357\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.021330511255655438\n",
      "        policy_loss: -0.04521089786430821\n",
      "        total_loss: 0.19537965534254909\n",
      "        vf_explained_var: 0.0010652057826519012\n",
      "        vf_loss: 0.22619245946407318\n",
      "    num_steps_sampled: 24000\n",
      "    num_steps_trained: 24000\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.412121212121214\n",
      "    ram_util_percent: 32.17474747474747\n",
      "  pid: 20860\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 9.93051463790204\n",
      "    mean_inference_ms: 3.1309787584611604\n",
      "    mean_processing_ms: 3.5039327107109943\n",
      "  time_since_restore: 441.38161063194275\n",
      "  time_this_iter_s: 69.73179054260254\n",
      "  time_total_s: 441.38161063194275\n",
      "  timers:\n",
      "    learn_throughput: 350.138\n",
      "    learn_time_ms: 11424.079\n",
      "    sample_throughput: 64.394\n",
      "    sample_time_ms: 62117.24\n",
      "    update_time_ms: 10.461\n",
      "  timestamp: 1601248472\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 24000\n",
      "  training_iteration: 6\n",
      "  trial_id: '29055_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.1/62.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/24 CPUs, 1/1 GPUs, 0.0/35.89 GiB heap, 0.0/12.35 GiB objects (0/1.0 GPUType:RTX)<br>Result logdir: /home/shyam/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_29055_00000</td><td>RUNNING </td><td>192.168.1.65:20860</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         441.382</td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\">0.424191</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MineRLNavigateDenseVectorObf-v0_29055_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-27_16-15-22\n",
      "  done: false\n",
      "  episode_len_mean: 6000.0\n",
      "  episode_reward_max: 3.2809486389160156\n",
      "  episode_reward_mean: 0.4241914749145508\n",
      "  episode_reward_min: -3.4253692626953125\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: cd52130b4cb14f188950a86134d66947\n",
      "  experiment_tag: '0'\n",
      "  hostname: kokkgoblin\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 1.0125000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 90.70811653137207\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.019655759446322918\n",
      "        policy_loss: -0.040245779731776565\n",
      "        total_loss: 0.05730344180483371\n",
      "        vf_explained_var: 0.00044705532491207123\n",
      "        vf_loss: 0.07764776237308979\n",
      "    num_steps_sampled: 28000\n",
      "    num_steps_trained: 28000\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.004225352112677\n",
      "    ram_util_percent: 32.25070422535211\n",
      "  pid: 20860\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 9.93051463790204\n",
      "    mean_inference_ms: 3.13097875846116\n",
      "    mean_processing_ms: 3.5039327107109948\n",
      "  time_since_restore: 490.67222237586975\n",
      "  time_this_iter_s: 49.290611743927\n",
      "  time_total_s: 490.67222237586975\n",
      "  timers:\n",
      "    learn_throughput: 351.092\n",
      "    learn_time_ms: 11393.038\n",
      "    sample_throughput: 68.165\n",
      "    sample_time_ms: 58681.357\n",
      "    update_time_ms: 10.326\n",
      "  timestamp: 1601248522\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 28000\n",
      "  training_iteration: 7\n",
      "  trial_id: '29055_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.2/62.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/24 CPUs, 1/1 GPUs, 0.0/35.89 GiB heap, 0.0/12.35 GiB objects (0/1.0 GPUType:RTX)<br>Result logdir: /home/shyam/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_29055_00000</td><td>RUNNING </td><td>192.168.1.65:20860</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         490.672</td><td style=\"text-align: right;\">28000</td><td style=\"text-align: right;\">0.424191</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MineRLNavigateDenseVectorObf-v0_29055_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-27_16-16-27\n",
      "  done: false\n",
      "  episode_len_mean: 6000.0\n",
      "  episode_reward_max: 3.2809486389160156\n",
      "  episode_reward_mean: 0.37872314453125\n",
      "  episode_reward_min: -3.4253692626953125\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 5\n",
      "  experiment_id: cd52130b4cb14f188950a86134d66947\n",
      "  experiment_tag: '0'\n",
      "  hostname: kokkgoblin\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 1.0125000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 90.55956053733826\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015016161458333954\n",
      "        policy_loss: -0.04013436194509268\n",
      "        total_loss: 0.2147175637073815\n",
      "        vf_explained_var: 0.0005682334303855896\n",
      "        vf_loss: 0.23964806273579597\n",
      "    num_steps_sampled: 32000\n",
      "    num_steps_trained: 32000\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.870967741935484\n",
      "    ram_util_percent: 32.33978494623655\n",
      "  pid: 20860\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 9.5012591821282\n",
      "    mean_inference_ms: 3.112635362028845\n",
      "    mean_processing_ms: 3.517567165928795\n",
      "  time_since_restore: 556.0529856681824\n",
      "  time_this_iter_s: 65.38076329231262\n",
      "  time_total_s: 556.0529856681824\n",
      "  timers:\n",
      "    learn_throughput: 354.287\n",
      "    learn_time_ms: 11290.286\n",
      "    sample_throughput: 68.734\n",
      "    sample_time_ms: 58195.119\n",
      "    update_time_ms: 10.186\n",
      "  timestamp: 1601248587\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 32000\n",
      "  training_iteration: 8\n",
      "  trial_id: '29055_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.2/62.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/24 CPUs, 1/1 GPUs, 0.0/35.89 GiB heap, 0.0/12.35 GiB objects (0/1.0 GPUType:RTX)<br>Result logdir: /home/shyam/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_29055_00000</td><td>RUNNING </td><td>192.168.1.65:20860</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         556.053</td><td style=\"text-align: right;\">32000</td><td style=\"text-align: right;\">0.378723</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MineRLNavigateDenseVectorObf-v0_29055_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-27_16-17-34\n",
      "  done: false\n",
      "  episode_len_mean: 6000.0\n",
      "  episode_reward_max: 3.2809486389160156\n",
      "  episode_reward_mean: 0.012468338012695312\n",
      "  episode_reward_min: -3.4253692626953125\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 6\n",
      "  experiment_id: cd52130b4cb14f188950a86134d66947\n",
      "  experiment_tag: '0'\n",
      "  hostname: kokkgoblin\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 1.0125000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 90.56985926628113\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.024545698892325163\n",
      "        policy_loss: -0.029902187583502382\n",
      "        total_loss: 0.28128266951534897\n",
      "        vf_explained_var: -1.862645149230957e-09\n",
      "        vf_loss: 0.28633233020082116\n",
      "    num_steps_sampled: 36000\n",
      "    num_steps_trained: 36000\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.56421052631579\n",
      "    ram_util_percent: 32.35473684210527\n",
      "  pid: 20860\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 9.172861643301047\n",
      "    mean_inference_ms: 3.098345050324274\n",
      "    mean_processing_ms: 3.5618065199503786\n",
      "  time_since_restore: 622.7679319381714\n",
      "  time_this_iter_s: 66.71494626998901\n",
      "  time_total_s: 622.7679319381714\n",
      "  timers:\n",
      "    learn_throughput: 355.686\n",
      "    learn_time_ms: 11245.87\n",
      "    sample_throughput: 69.049\n",
      "    sample_time_ms: 57929.685\n",
      "    update_time_ms: 10.101\n",
      "  timestamp: 1601248654\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 36000\n",
      "  training_iteration: 9\n",
      "  trial_id: '29055_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.3/62.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/24 CPUs, 1/1 GPUs, 0.0/35.89 GiB heap, 0.0/12.35 GiB objects (0/1.0 GPUType:RTX)<br>Result logdir: /home/shyam/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_29055_00000</td><td>RUNNING </td><td>192.168.1.65:20860</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         622.768</td><td style=\"text-align: right;\">36000</td><td style=\"text-align: right;\">0.0124683</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MineRLNavigateDenseVectorObf-v0_29055_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-27_16-18-25\n",
      "  done: true\n",
      "  episode_len_mean: 6000.0\n",
      "  episode_reward_max: 3.2809486389160156\n",
      "  episode_reward_mean: 0.012468338012695312\n",
      "  episode_reward_min: -3.4253692626953125\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 6\n",
      "  experiment_id: cd52130b4cb14f188950a86134d66947\n",
      "  experiment_tag: '0'\n",
      "  hostname: kokkgoblin\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 1.5187500000000003\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 90.50423455238342\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013474712934112176\n",
      "        policy_loss: -0.04066264955326915\n",
      "        total_loss: 0.22766426880843937\n",
      "        vf_explained_var: 7.715635001659393e-05\n",
      "        vf_loss: 0.24786219839006662\n",
      "    num_steps_sampled: 40000\n",
      "    num_steps_trained: 40000\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.68767123287671\n",
      "    ram_util_percent: 32.38630136986301\n",
      "  pid: 20860\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 9.172861643301049\n",
      "    mean_inference_ms: 3.098345050324274\n",
      "    mean_processing_ms: 3.561806519950379\n",
      "  time_since_restore: 673.592369556427\n",
      "  time_this_iter_s: 50.824437618255615\n",
      "  time_total_s: 673.592369556427\n",
      "  timers:\n",
      "    learn_throughput: 356.526\n",
      "    learn_time_ms: 11219.392\n",
      "    sample_throughput: 71.277\n",
      "    sample_time_ms: 56119.262\n",
      "    update_time_ms: 10.035\n",
      "  timestamp: 1601248705\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 40000\n",
      "  training_iteration: 10\n",
      "  trial_id: '29055_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.0/62.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/24 CPUs, 0/1 GPUs, 0.0/35.89 GiB heap, 0.0/12.35 GiB objects (0/1.0 GPUType:RTX)<br>Result logdir: /home/shyam/ray_results/PPO<br>Number of trials: 1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_29055_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         673.592</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\">0.0124683</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.4/62.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/24 CPUs, 0/1 GPUs, 0.0/35.89 GiB heap, 0.0/12.35 GiB objects (0/1.0 GPUType:RTX)<br>Result logdir: /home/shyam/ray_results/PPO<br>Number of trials: 1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_29055_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         673.592</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\">0.0124683</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f8e005e5fa0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m *** Aborted at 1601248708 (unix time) try \"date -d @1601248708\" if you are using GNU date ***\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m PC: @                0x0 (unknown)\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m *** SIGSEGV (@0x7fe993fff9d0) received by PID 22551 (TID 0x7fe9b6ea8740) from PID 18446744071897610704; stack trace: ***\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x7fe9b6a998a0 (unknown)\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x7fe9b6a8fbd8 __GI___pthread_timedjoin_ex\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x7fe9b487a2d3 std::thread::join()\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x7fe9b4da43a3 ray::gcs::GlobalStateAccessor::Disconnect()\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x7fe9b4c4918c __pyx_pw_3ray_7_raylet_19GlobalStateAccessor_5disconnect()\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc240e6a method_vectorcall_NOARGS\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc1d175e _PyEval_EvalFrameDefault.cold.2790\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc25c86b _PyFunction_Vectorcall.localalias.355\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc1d175e _PyEval_EvalFrameDefault.cold.2790\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc25ba92 _PyEval_EvalCodeWithName\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc25c943 _PyFunction_Vectorcall.localalias.355\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc1cfb84 _PyEval_EvalFrameDefault.cold.2790\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc25ba92 _PyEval_EvalCodeWithName\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc25c943 _PyFunction_Vectorcall.localalias.355\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc20e041 PyVectorcall_Call\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc19528d _PyErr_CheckSignals.cold.2277\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc1befe6 time_sleep.cold.2620\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc211825 cfunction_vectorcall_O\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc1d177f _PyEval_EvalFrameDefault.cold.2790\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc25bf9f _PyEval_EvalCodeWithName\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc25c943 _PyFunction_Vectorcall.localalias.355\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc20e041 PyVectorcall_Call\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc29399b _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc25c86b _PyFunction_Vectorcall.localalias.355\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc1d175e _PyEval_EvalFrameDefault.cold.2790\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc25ba92 _PyEval_EvalCodeWithName\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc25cd20 method_vectorcall\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc1d111a _PyEval_EvalFrameDefault.cold.2790\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc25c86b _PyFunction_Vectorcall.localalias.355\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc1d175e _PyEval_EvalFrameDefault.cold.2790\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc25d60d _PyObject_FastCallDict\n",
      "\u001b[2m\u001b[36m(pid=20870)\u001b[0m     @     0x562bbc25d733 _PyObject_Call_Prepend\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from ray.rllib.agents.dqn import DQNTrainer\n",
    "\n",
    "tune.run(\"PPO\",\n",
    "         config={\"env\": \"MineRLNavigateDenseVectorObf-v0\",\n",
    "                 \"monitor\":False, \n",
    "                 \"num_gpus\": 1,\n",
    "                 \"num_workers\": 1,\n",
    "                 \"num_envs_per_worker\":1,\n",
    "                 \"eager\":False,\n",
    "                 \"use_pytorch\":True,\n",
    "#                  \"model\": {\n",
    "#                     \"custom_model\": \"fc_pov\",\n",
    "#                     }\n",
    "                 },\n",
    "         stop={\"training_iteration\": 10})  \n",
    "# Config notes:\n",
    "# \"log_level\": \"INFO\" for verbose,\n",
    "# \"eager\": True for eager execution,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/shyam/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-11-68980fa6ca4b>\", line 16, in <module>\n",
      "    obs, reward, done, info = env.step(\n",
      "  File \"/home/shyam/anaconda3/envs/py38/lib/python3.8/site-packages/gym/wrappers/time_limit.py\", line 16, in step\n",
      "    observation, reward, done, info = self.env.step(action)\n",
      "  File \"/home/shyam/anaconda3/envs/py38/lib/python3.8/site-packages/minerl/env/core.py\", line 623, in step\n",
      "    obs = comms.recv_message(self.client_socket)\n",
      "  File \"/home/shyam/anaconda3/envs/py38/lib/python3.8/site-packages/minerl/env/comms.py\", line 62, in recv_message\n",
      "    lengthbuf = recvall(sock, 4)\n",
      "  File \"/home/shyam/anaconda3/envs/py38/lib/python3.8/site-packages/minerl/env/comms.py\", line 72, in recvall\n",
      "    newbuf = sock.recv(count)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shyam/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shyam/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/shyam/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/shyam/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/shyam/anaconda3/envs/py38/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/shyam/anaconda3/envs/py38/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/shyam/anaconda3/envs/py38/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/shyam/anaconda3/envs/py38/lib/python3.8/inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/shyam/anaconda3/envs/py38/lib/python3.8/posixpath.py\", line 391, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/shyam/anaconda3/envs/py38/lib/python3.8/posixpath.py\", line 425, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/shyam/anaconda3/envs/py38/lib/python3.8/posixpath.py\", line 167, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-68980fa6ca4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     obs, reward, done, info = env.step(\n\u001b[0m\u001b[1;32m     17\u001b[0m         action)\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/minerl/env/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    622\u001b[0m                 \u001b[0;31m# Receive the observation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m                 \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient_socket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/minerl/env/comms.py\u001b[0m in \u001b[0;36mrecv_message\u001b[0;34m(sock)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecv_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mlengthbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecvall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlengthbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/minerl/env/comms.py\u001b[0m in \u001b[0;36mrecvall\u001b[0;34m(sock, count)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mnewbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnewbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2044\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2046\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2047\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1433\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1435\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1436\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1336\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1193\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import minerl\n",
    "import gym\n",
    "env = gym.make('MineRLNavigateDense-v0')\n",
    "\n",
    "\n",
    "obs = env.reset()\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    action = env.action_space.sample() \n",
    " \n",
    "    # One can also take a no_op action with\n",
    "    # action =env.action_space.noop()\n",
    "    \n",
    " \n",
    "    obs, reward, done, info = env.step(\n",
    "        action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38] *",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
