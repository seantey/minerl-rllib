{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-27 15:36:06,400\tINFO resource_spec.py:231 -- Starting Ray with 13.87 GiB memory available for workers and up to 6.95 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-09-27 15:36:06,921\tINFO services.py:1193 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8268\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.7.73',\n",
       " 'raylet_ip_address': '192.168.7.73',\n",
       " 'redis_address': '192.168.7.73:52651',\n",
       " 'object_store_address': '/tmp/ray/session_2020-09-27_15-36-06_399253_34064/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-09-27_15-36-06_399253_34064/sockets/raylet',\n",
       " 'webui_url': 'localhost:8268',\n",
       " 'session_dir': '/tmp/ray/session_2020-09-27_15-36-06_399253_34064'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Ray\n",
    "ray.shutdown()\n",
    "ray.init(ignore_reinit_error=True,num_cpus=8, num_gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object_store_memory': 98.0,\n",
       " 'GPUType:GTX': 1.0,\n",
       " 'node:192.168.7.73': 1.0,\n",
       " 'memory': 284.0,\n",
       " 'CPU': 8.0,\n",
       " 'GPU': 1.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://docs.ray.io/en/latest/tune/user-guide.html#parallelism-gpus\n",
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard URL: http://localhost:8268\n"
     ]
    }
   ],
   "source": [
    "print(\"Dashboard URL: http://{}\".format(ray.get_webui_url()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register MineRL Gym Environment to RLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minerl_rllib.envs import register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering Environment Name: MineRLTreechopVectorObf-v0\n",
      "Registering Environment Name: MineRLNavigateVectorObf-v0\n",
      "Registering Environment Name: MineRLNavigateExtremeVectorObf-v0\n",
      "Registering Environment Name: MineRLNavigateDenseVectorObf-v0\n",
      "Registering Environment Name: MineRLNavigateExtremeDenseVectorObf-v0\n",
      "Registering Environment Name: MineRLObtainDiamondVectorObf-v0\n",
      "Registering Environment Name: MineRLObtainDiamondDenseVectorObf-v0\n",
      "Registering Environment Name: MineRLObtainIronPickaxeVectorObf-v0\n",
      "Registering Environment Name: MineRLObtainIronPickaxeDenseVectorObf-v0\n",
      "Registering Environment Name: MineRLObtainDiamondSurvivalVectorObf-v0\n"
     ]
    }
   ],
   "source": [
    "register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.8/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.87 GiB heap, 0.0/4.79 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/blackbox/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_d61ec_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m WARNING:tensorflow:From /home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m /home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m 2020-09-27 15:36:11,007\tWARNING deprecation.py:30 -- DeprecationWarning: `use_pytorch` has been deprecated. Use `framework=torch` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m 2020-09-27 15:36:11,007\tWARNING deprecation.py:30 -- DeprecationWarning: `eager` has been deprecated. Use `framework=tfe` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m 2020-09-27 15:36:11,008\tINFO trainer.py:632 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m 2020-09-27 15:36:48,618\tINFO trainable.py:251 -- Trainable.setup took 38.501 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m 2020-09-27 15:36:48,618\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=36819)\u001b[0m WARNING:tensorflow:From /home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=36819)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=36819)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=36819)\u001b[0m /home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=36819)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=36819)\u001b[0m /home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/ray/rllib/utils/torch_ops.py:149: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=36819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=36819)\u001b[0m /home/blackbox/anaconda3/envs/minerl/lib/python3.7/site-packages/minerl/herobraine/wrappers/obfuscation_wrapper.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
      "\u001b[2m\u001b[36m(pid=36819)\u001b[0m   x[..., a:b] = e_x / e_x.sum(axis=-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MineRLNavigateDenseVectorObf-v0_d61ec_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-27_15-38-35\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: 9dbd458028cd45bc961432404919f239\n",
      "  experiment_tag: '0'\n",
      "  hostname: blackbox\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.2\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 90.98131036758423\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01715636212611571\n",
      "        policy_loss: -0.02366898671607487\n",
      "        total_loss: 0.19437148375436664\n",
      "        vf_explained_var: 0.00027029216289520264\n",
      "        vf_loss: 0.2146091996692121\n",
      "    num_steps_sampled: 4000\n",
      "    num_steps_trained: 4000\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.7.73\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.4797385620915\n",
      "    ram_util_percent: 56.319607843137256\n",
      "  pid: 36817\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 106.74650979042053\n",
      "  time_this_iter_s: 106.74650979042053\n",
      "  time_total_s: 106.74650979042053\n",
      "  timers:\n",
      "    learn_throughput: 324.442\n",
      "    learn_time_ms: 12328.849\n",
      "    sample_throughput: 42.373\n",
      "    sample_time_ms: 94398.77\n",
      "    update_time_ms: 10.154\n",
      "  timestamp: 1601246315\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4000\n",
      "  training_iteration: 1\n",
      "  trial_id: d61ec_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.2/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.87 GiB heap, 0.0/4.79 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/blackbox/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_d61ec_00000</td><td>RUNNING </td><td>192.168.7.73:36817</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         106.747</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">     nan</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MineRLNavigateDenseVectorObf-v0_d61ec_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-27_15-39-48\n",
      "  done: false\n",
      "  episode_len_mean: 6000.0\n",
      "  episode_reward_max: 8.398029327392578\n",
      "  episode_reward_mean: 8.398029327392578\n",
      "  episode_reward_min: 8.398029327392578\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1\n",
      "  experiment_id: 9dbd458028cd45bc961432404919f239\n",
      "  experiment_tag: '0'\n",
      "  hostname: blackbox\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.2\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 90.81255340576172\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.018112751422449946\n",
      "        policy_loss: -0.021517517016036436\n",
      "        total_loss: 0.19912273326190189\n",
      "        vf_explained_var: -5.587935447692871e-09\n",
      "        vf_loss: 0.21701770182698965\n",
      "    num_steps_sampled: 8000\n",
      "    num_steps_trained: 8000\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.7.73\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.12115384615385\n",
      "    ram_util_percent: 60.87403846153847\n",
      "  pid: 36817\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 8.810726795594643\n",
      "    mean_inference_ms: 3.0832150596005516\n",
      "    mean_processing_ms: 2.805554319986506\n",
      "  time_since_restore: 179.66740775108337\n",
      "  time_this_iter_s: 72.92089796066284\n",
      "  time_total_s: 179.66740775108337\n",
      "  timers:\n",
      "    learn_throughput: 333.811\n",
      "    learn_time_ms: 11982.827\n",
      "    sample_throughput: 51.393\n",
      "    sample_time_ms: 77832.009\n",
      "    update_time_ms: 9.758\n",
      "  timestamp: 1601246388\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8000\n",
      "  training_iteration: 2\n",
      "  trial_id: d61ec_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.1/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.87 GiB heap, 0.0/4.79 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/blackbox/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_d61ec_00000</td><td>RUNNING </td><td>192.168.7.73:36817</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         179.667</td><td style=\"text-align: right;\">8000</td><td style=\"text-align: right;\"> 8.39803</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MineRLNavigateDenseVectorObf-v0_d61ec_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-27_15-40-57\n",
      "  done: false\n",
      "  episode_len_mean: 6000.0\n",
      "  episode_reward_max: 8.398029327392578\n",
      "  episode_reward_mean: 6.504926681518555\n",
      "  episode_reward_min: 4.611824035644531\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 2\n",
      "  experiment_id: 9dbd458028cd45bc961432404919f239\n",
      "  experiment_tag: '0'\n",
      "  hostname: blackbox\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.2\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 90.89071488380432\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.018751149938907474\n",
      "        policy_loss: -0.025549048092216253\n",
      "        total_loss: 0.1925485001411289\n",
      "        vf_explained_var: -5.587935447692871e-09\n",
      "        vf_loss: 0.2143473206087947\n",
      "    num_steps_sampled: 12000\n",
      "    num_steps_trained: 12000\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.7.73\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.285858585858584\n",
      "    ram_util_percent: 61.36060606060607\n",
      "  pid: 36817\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 8.459414480673187\n",
      "    mean_inference_ms: 3.073890639998093\n",
      "    mean_processing_ms: 3.1216977648665782\n",
      "  time_since_restore: 249.22741603851318\n",
      "  time_this_iter_s: 69.56000828742981\n",
      "  time_total_s: 249.22741603851318\n",
      "  timers:\n",
      "    learn_throughput: 337.655\n",
      "    learn_time_ms: 11846.4\n",
      "    sample_throughput: 56.171\n",
      "    sample_time_ms: 71210.685\n",
      "    update_time_ms: 9.688\n",
      "  timestamp: 1601246457\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12000\n",
      "  training_iteration: 3\n",
      "  trial_id: d61ec_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.2/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.87 GiB heap, 0.0/4.79 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/blackbox/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_d61ec_00000</td><td>RUNNING </td><td>192.168.7.73:36817</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         249.227</td><td style=\"text-align: right;\">12000</td><td style=\"text-align: right;\"> 6.50493</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MineRLNavigateDenseVectorObf-v0_d61ec_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-27_15-41-45\n",
      "  done: false\n",
      "  episode_len_mean: 6000.0\n",
      "  episode_reward_max: 8.398029327392578\n",
      "  episode_reward_mean: 6.504926681518555\n",
      "  episode_reward_min: 4.611824035644531\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 2\n",
      "  experiment_id: 9dbd458028cd45bc961432404919f239\n",
      "  experiment_tag: '0'\n",
      "  hostname: blackbox\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.2\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 90.98683595657349\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01945393200730905\n",
      "        policy_loss: -0.019779433641815558\n",
      "        total_loss: 0.12801506533287466\n",
      "        vf_explained_var: -3.725290298461914e-09\n",
      "        vf_loss: 0.14390371250919998\n",
      "    num_steps_sampled: 16000\n",
      "    num_steps_trained: 16000\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.7.73\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.479411764705887\n",
      "    ram_util_percent: 61.708823529411774\n",
      "  pid: 36817\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 8.459414480673187\n",
      "    mean_inference_ms: 3.073890639998093\n",
      "    mean_processing_ms: 3.1216977648665782\n",
      "  time_since_restore: 297.00483226776123\n",
      "  time_this_iter_s: 47.77741622924805\n",
      "  time_total_s: 297.00483226776123\n",
      "  timers:\n",
      "    learn_throughput: 336.958\n",
      "    learn_time_ms: 11870.904\n",
      "    sample_throughput: 64.142\n",
      "    sample_time_ms: 62361.585\n",
      "    update_time_ms: 9.795\n",
      "  timestamp: 1601246505\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16000\n",
      "  training_iteration: 4\n",
      "  trial_id: d61ec_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.3/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.87 GiB heap, 0.0/4.79 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/blackbox/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_d61ec_00000</td><td>RUNNING </td><td>192.168.7.73:36817</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         297.005</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\"> 6.50493</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MineRLNavigateDenseVectorObf-v0_d61ec_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-27_15-42-56\n",
      "  done: false\n",
      "  episode_len_mean: 6000.0\n",
      "  episode_reward_max: 10.422988891601562\n",
      "  episode_reward_mean: 7.810947418212891\n",
      "  episode_reward_min: 4.611824035644531\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 3\n",
      "  experiment_id: 9dbd458028cd45bc961432404919f239\n",
      "  experiment_tag: '0'\n",
      "  hostname: blackbox\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.2\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 90.83043909072876\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.021363594627473503\n",
      "        policy_loss: -0.03676201368216425\n",
      "        total_loss: 0.07252138122566976\n",
      "        vf_explained_var: -9.313225746154785e-09\n",
      "        vf_loss: 0.105010672705248\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 20000\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.7.73\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.211764705882345\n",
      "    ram_util_percent: 62.080392156862764\n",
      "  pid: 36817\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 8.056939179552083\n",
      "    mean_inference_ms: 3.0716793667026874\n",
      "    mean_processing_ms: 3.139651261258725\n",
      "  time_since_restore: 368.1550307273865\n",
      "  time_this_iter_s: 71.15019845962524\n",
      "  time_total_s: 368.1550307273865\n",
      "  timers:\n",
      "    learn_throughput: 336.797\n",
      "    learn_time_ms: 11876.608\n",
      "    sample_throughput: 64.793\n",
      "    sample_time_ms: 61735.465\n",
      "    update_time_ms: 9.899\n",
      "  timestamp: 1601246576\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 5\n",
      "  trial_id: d61ec_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.5/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.87 GiB heap, 0.0/4.79 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/blackbox/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_d61ec_00000</td><td>RUNNING </td><td>192.168.7.73:36817</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         368.155</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\"> 7.81095</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MineRLNavigateDenseVectorObf-v0_d61ec_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-27_15-44-08\n",
      "  done: false\n",
      "  episode_len_mean: 6000.0\n",
      "  episode_reward_max: 10.422988891601562\n",
      "  episode_reward_mean: 5.402642250061035\n",
      "  episode_reward_min: -1.8222732543945312\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 4\n",
      "  experiment_id: 9dbd458028cd45bc961432404919f239\n",
      "  experiment_tag: '0'\n",
      "  hostname: blackbox\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.30000000000000004\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 90.82030630111694\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.019245401374064386\n",
      "        policy_loss: -0.02660228224704042\n",
      "        total_loss: 0.1716480302857235\n",
      "        vf_explained_var: 2.89231538772583e-05\n",
      "        vf_loss: 0.19247668841853738\n",
      "    num_steps_sampled: 24000\n",
      "    num_steps_trained: 24000\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.7.73\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.24509803921569\n",
      "    ram_util_percent: 62.323529411764724\n",
      "  pid: 36817\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.811334072980882\n",
      "    mean_inference_ms: 3.0679690902767334\n",
      "    mean_processing_ms: 3.248813655609062\n",
      "  time_since_restore: 439.52924728393555\n",
      "  time_this_iter_s: 71.37421655654907\n",
      "  time_total_s: 439.52924728393555\n",
      "  timers:\n",
      "    learn_throughput: 336.072\n",
      "    learn_time_ms: 11902.221\n",
      "    sample_throughput: 65.217\n",
      "    sample_time_ms: 61333.677\n",
      "    update_time_ms: 9.819\n",
      "  timestamp: 1601246648\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 24000\n",
      "  training_iteration: 6\n",
      "  trial_id: d61ec_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.4/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.87 GiB heap, 0.0/4.79 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/blackbox/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_d61ec_00000</td><td>RUNNING </td><td>192.168.7.73:36817</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         439.529</td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\"> 5.40264</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MineRLNavigateDenseVectorObf-v0_d61ec_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-27_15-45-02\n",
      "  done: false\n",
      "  episode_len_mean: 6000.0\n",
      "  episode_reward_max: 10.422988891601562\n",
      "  episode_reward_mean: 5.402642250061035\n",
      "  episode_reward_min: -1.8222732543945312\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 4\n",
      "  experiment_id: 9dbd458028cd45bc961432404919f239\n",
      "  experiment_tag: '0'\n",
      "  hostname: blackbox\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.30000000000000004\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 90.66910338401794\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01857259892858565\n",
      "        policy_loss: -0.02692241972545162\n",
      "        total_loss: 0.2055343603133224\n",
      "        vf_explained_var: 3.711506724357605e-05\n",
      "        vf_loss: 0.22688500210642815\n",
      "    num_steps_sampled: 28000\n",
      "    num_steps_trained: 28000\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.7.73\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.903896103896102\n",
      "    ram_util_percent: 62.17012987012988\n",
      "  pid: 36817\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.811334072980882\n",
      "    mean_inference_ms: 3.0679690902767334\n",
      "    mean_processing_ms: 3.2488136556090614\n",
      "  time_since_restore: 493.5990970134735\n",
      "  time_this_iter_s: 54.069849729537964\n",
      "  time_total_s: 493.5990970134735\n",
      "  timers:\n",
      "    learn_throughput: 337.405\n",
      "    learn_time_ms: 11855.175\n",
      "    sample_throughput: 68.213\n",
      "    sample_time_ms: 58640.034\n",
      "    update_time_ms: 9.72\n",
      "  timestamp: 1601246702\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 28000\n",
      "  training_iteration: 7\n",
      "  trial_id: d61ec_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.4/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.87 GiB heap, 0.0/4.79 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/blackbox/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_d61ec_00000</td><td>RUNNING </td><td>192.168.7.73:36817</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         493.599</td><td style=\"text-align: right;\">28000</td><td style=\"text-align: right;\"> 5.40264</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MineRLNavigateDenseVectorObf-v0_d61ec_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-27_15-46-14\n",
      "  done: false\n",
      "  episode_len_mean: 6000.0\n",
      "  episode_reward_max: 10.422988891601562\n",
      "  episode_reward_mean: 4.879722595214844\n",
      "  episode_reward_min: -1.8222732543945312\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 5\n",
      "  experiment_id: 9dbd458028cd45bc961432404919f239\n",
      "  experiment_tag: '0'\n",
      "  hostname: blackbox\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.30000000000000004\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 90.75928354263306\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.017608505382668227\n",
      "        policy_loss: -0.026321040000766516\n",
      "        total_loss: 0.1266341721639037\n",
      "        vf_explained_var: 0.0006932355463504791\n",
      "        vf_loss: 0.1476726580876857\n",
      "    num_steps_sampled: 32000\n",
      "    num_steps_trained: 32000\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.7.73\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.44271844660194\n",
      "    ram_util_percent: 61.966990291262114\n",
      "  pid: 36817\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.658498753275181\n",
      "    mean_inference_ms: 3.0632771698927206\n",
      "    mean_processing_ms: 3.2763670740361723\n",
      "  time_since_restore: 565.5632169246674\n",
      "  time_this_iter_s: 71.96411991119385\n",
      "  time_total_s: 565.5632169246674\n",
      "  timers:\n",
      "    learn_throughput: 338.167\n",
      "    learn_time_ms: 11828.468\n",
      "    sample_throughput: 67.972\n",
      "    sample_time_ms: 58848.001\n",
      "    update_time_ms: 9.74\n",
      "  timestamp: 1601246774\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 32000\n",
      "  training_iteration: 8\n",
      "  trial_id: d61ec_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.3/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.87 GiB heap, 0.0/4.79 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/blackbox/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_d61ec_00000</td><td>RUNNING </td><td>192.168.7.73:36817</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         565.563</td><td style=\"text-align: right;\">32000</td><td style=\"text-align: right;\"> 4.87972</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MineRLNavigateDenseVectorObf-v0_d61ec_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-27_15-47-27\n",
      "  done: false\n",
      "  episode_len_mean: 6000.0\n",
      "  episode_reward_max: 10.422988891601562\n",
      "  episode_reward_mean: 3.558629353841146\n",
      "  episode_reward_min: -3.0468368530273438\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 6\n",
      "  experiment_id: 9dbd458028cd45bc961432404919f239\n",
      "  experiment_tag: '0'\n",
      "  hostname: blackbox\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.30000000000000004\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 90.59759783744812\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01845002215122804\n",
      "        policy_loss: -0.028947473678272218\n",
      "        total_loss: 0.1415132216643542\n",
      "        vf_explained_var: 0.0014839861541986465\n",
      "        vf_loss: 0.16492568934336305\n",
      "    num_steps_sampled: 36000\n",
      "    num_steps_trained: 36000\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.7.73\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.325000000000003\n",
      "    ram_util_percent: 61.87596153846154\n",
      "  pid: 36817\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.547570272075863\n",
      "    mean_inference_ms: 3.0587418106336455\n",
      "    mean_processing_ms: 3.3392009602560297\n",
      "  time_since_restore: 638.7105317115784\n",
      "  time_this_iter_s: 73.14731478691101\n",
      "  time_total_s: 638.7105317115784\n",
      "  timers:\n",
      "    learn_throughput: 338.767\n",
      "    learn_time_ms: 11807.538\n",
      "    sample_throughput: 67.635\n",
      "    sample_time_ms: 59141.33\n",
      "    update_time_ms: 9.711\n",
      "  timestamp: 1601246847\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 36000\n",
      "  training_iteration: 9\n",
      "  trial_id: d61ec_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.3/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.87 GiB heap, 0.0/4.79 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/blackbox/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_d61ec_00000</td><td>RUNNING </td><td>192.168.7.73:36817</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         638.711</td><td style=\"text-align: right;\">36000</td><td style=\"text-align: right;\"> 3.55863</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MineRLNavigateDenseVectorObf-v0_d61ec_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-09-27_15-48-25\n",
      "  done: true\n",
      "  episode_len_mean: 6000.0\n",
      "  episode_reward_max: 10.422988891601562\n",
      "  episode_reward_mean: 3.558629353841146\n",
      "  episode_reward_min: -3.0468368530273438\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 6\n",
      "  experiment_id: 9dbd458028cd45bc961432404919f239\n",
      "  experiment_tag: '0'\n",
      "  hostname: blackbox\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.30000000000000004\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 90.6822600364685\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015533475758275017\n",
      "        policy_loss: -0.021596549486275762\n",
      "        total_loss: 0.07926662801764905\n",
      "        vf_explained_var: -1.4901161193847656e-08\n",
      "        vf_loss: 0.09620313555933535\n",
      "    num_steps_sampled: 40000\n",
      "    num_steps_trained: 40000\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.7.73\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.907228915662653\n",
      "    ram_util_percent: 61.92650602409637\n",
      "  pid: 36817\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.5475702720758635\n",
      "    mean_inference_ms: 3.0587418106336455\n",
      "    mean_processing_ms: 3.3392009602560297\n",
      "  time_since_restore: 696.9690279960632\n",
      "  time_this_iter_s: 58.25849628448486\n",
      "  time_total_s: 696.9690279960632\n",
      "  timers:\n",
      "    learn_throughput: 339.306\n",
      "    learn_time_ms: 11788.775\n",
      "    sample_throughput: 69.098\n",
      "    sample_time_ms: 57889.198\n",
      "    update_time_ms: 9.66\n",
      "  timestamp: 1601246905\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 40000\n",
      "  training_iteration: 10\n",
      "  trial_id: d61ec_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.3/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/13.87 GiB heap, 0.0/4.79 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/blackbox/ray_results/PPO<br>Number of trials: 1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_d61ec_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         696.969</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\"> 3.55863</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.3/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/13.87 GiB heap, 0.0/4.79 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/blackbox/ray_results/PPO<br>Number of trials: 1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                     </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MineRLNavigateDenseVectorObf-v0_d61ec_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         696.969</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\"> 3.55863</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m *** Aborted at 1601246908 (unix time) try \"date -d @1601246908\" if you are using GNU date ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7fb58c58b5d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m PC: @                0x0 (unknown)\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m *** SIGSEGV (@0x7f8f0a43d9d0) received by PID 37011 (TID 0x7f90f1889740) from PID 172218832; stack trace: ***\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x7f90f1bfa3c0 (unknown)\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x7f90f1befaab __pthread_clockjoin_ex\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x7f90ef7c52d3 std::thread::join()\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x7f90efcf6493 ray::gcs::GlobalStateAccessor::Disconnect()\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x7f90efb95fbc __pyx_pw_3ray_7_raylet_19GlobalStateAccessor_5disconnect()\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b615828b71 _PyMethodDef_RawFastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b61582faef _PyMethodDescr_FastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b61589437c _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b61582820b _PyFunction_FastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b61588fe70 _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b6157d82b9 _PyEval_EvalCodeWithName\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b615828435 _PyFunction_FastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b61588fbe6 _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b6157d82b9 _PyEval_EvalCodeWithName\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b6157d93e5 _PyFunction_FastCallDict\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b61583dc70 PyErr_CheckSignals\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b6158499c6 time_sleep\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b615828abd _PyMethodDef_RawFastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b615828db1 _PyCFunction_FastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b6158945be _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b6157d8b00 _PyEval_EvalCodeWithName\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b6157d93e5 _PyFunction_FastCallDict\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b61589151a _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b61582820b _PyFunction_FastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b61588fe70 _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b61582820b _PyFunction_FastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b61588fe70 _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b61582820b _PyFunction_FastCallKeywords\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b61588fe70 _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b6157d931b _PyFunction_FastCallDict\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b6157f7b93 _PyObject_Call_Prepend\n",
      "\u001b[2m\u001b[36m(pid=36817)\u001b[0m     @     0x55b61582f0aa slot_tp_init\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0927 15:48:28.989035 36794 36794 process.cc:434] Failed to kill process 36819 with error system:3: No such process\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "# https://docs.ray.io/en/latest/rllib-training.html#tuned-examples\n",
    "\n",
    "tune.run(\"PPO\",\n",
    "         config={\"env\": \"MineRLNavigateDenseVectorObf-v0\",\n",
    "                 \"num_gpus\": 1,\n",
    "                 \"num_workers\": 1,\n",
    "                 \"num_envs_per_worker\": 1,\n",
    "                 \"eager\": False,\n",
    "                 \"use_pytorch\": True,\n",
    "#                  'monitor':True, \n",
    "#                  \"model\": {\n",
    "#                     \"custom_model\": \"fc_pov\",\n",
    "#                     }\n",
    "                 }\n",
    "         ,stop={\"training_iteration\": 10})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
